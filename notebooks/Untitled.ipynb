{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math, copy, time\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "seaborn.set_context(context=\"talk\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A standard Encoder-Decoder architecture. Base for this and many \n",
    "    other models.\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = src_embed\n",
    "        self.tgt_embed = tgt_embed\n",
    "        self.generator = generator\n",
    "        \n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        \"Take in and process masked src and target sequences.\"\n",
    "        return self.decode(self.encode(src, src_mask), src_mask,\n",
    "                            tgt, tgt_mask)\n",
    "    \n",
    "    def encode(self, src, src_mask):\n",
    "        return self.encoder(self.src_embed(src), src_mask)\n",
    "    \n",
    "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
    "        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"Define standard linear + softmax generation step.\"\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Generator, self).__init__()\n",
    "        self.proj = nn.Linear(d_model, vocab)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.log_softmax(self.proj(x), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"Core encoder is a stack of N layers\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        \"Pass the input (and mask) through each layer in turn.\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \"Construct a layernorm module (See citation for details).\"\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual connection followed by a layer norm.\n",
    "    Note for code simplicity the norm is first as opposed to last.\n",
    "    \"\"\"\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        \"Apply residual connection to any sublayer with the same size.\"\n",
    "        return x + self.dropout(sublayer(self.norm(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    \"Encoder is made up of self-attn and feed forward (defined below)\"\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"Follow Figure 1 (left) for connections.\"\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
    "        return self.sublayer[1](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"Generic N layer decoder with masking.\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, src_mask, tgt_mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    \"Decoder is made of self-attn, src-attn, and feed forward (defined below)\"\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
    " \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        \"Follow Figure 1 (right) for connections.\"\n",
    "        m = memory\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
    "        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n",
    "        return self.sublayer[2](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsequent_mask(size):\n",
    "    \"Mask out subsequent positions.\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return torch.from_numpy(subsequent_mask) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
    "             / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    p_attn = F.softmax(scores, dim = -1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"Implements Figure 2\"\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "        \n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k \n",
    "        query, key, value = \\\n",
    "            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "             for l, x in zip(self.linears, (query, key, value))]\n",
    "        \n",
    "        # 2) Apply attention on all the projected vectors in batch. \n",
    "        x, self.attn = attention(query, key, value, mask=mask, \n",
    "                                 dropout=self.dropout)\n",
    "        \n",
    "        # 3) \"Concat\" using a view and apply a final linear. \n",
    "        x = x.transpose(1, 2).contiguous() \\\n",
    "             .view(nbatches, -1, self.h * self.d_k)\n",
    "        return self.linears[-1](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"Implements FFN equation.\"\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.lut = nn.Embedding(vocab, d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lut(x) * math.sqrt(self.d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) *\n",
    "                             -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + Variable(self.pe[:, :x.size(1)], \n",
    "                         requires_grad=False)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(src_vocab, tgt_vocab, N=6, \n",
    "               d_model=512, d_ff=2048, h=8, dropout=0.1):\n",
    "    \"Helper: Construct a model from hyperparameters.\"\n",
    "    c = copy.deepcopy\n",
    "    attn = MultiHeadedAttention(h, d_model)\n",
    "    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "    position = PositionalEncoding(d_model, dropout)\n",
    "    model = EncoderDecoder(\n",
    "        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
    "        Decoder(DecoderLayer(d_model, c(attn), c(attn), \n",
    "                             c(ff), dropout), N),\n",
    "        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n",
    "        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),\n",
    "        Generator(d_model, tgt_vocab))\n",
    "    \n",
    "    # This was important from their code. \n",
    "    # Initialize parameters with Glorot / fan_avg.\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform(p)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leon/anaconda3/envs/ntm/lib/python3.7/site-packages/ipykernel_launcher.py:20: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
     ]
    }
   ],
   "source": [
    "tmp_model = make_model(10, 10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch:\n",
    "    \"Object for holding a batch of data with mask during training.\"\n",
    "    def __init__(self, src, trg=None, pad=0):\n",
    "        self.src = src\n",
    "        self.src_mask = (src != pad).unsqueeze(-2)\n",
    "        if trg is not None:\n",
    "            self.trg = trg[:, :-1]\n",
    "            self.trg_y = trg[:, 1:]\n",
    "            self.trg_mask = \\\n",
    "                self.make_std_mask(self.trg, pad)\n",
    "            self.ntokens = (self.trg_y != pad).data.sum()\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_std_mask(tgt, pad):\n",
    "        \"Create a mask to hide padding and future words.\"\n",
    "        tgt_mask = (tgt != pad).unsqueeze(-2)\n",
    "        tgt_mask = tgt_mask & Variable(\n",
    "            subsequent_mask(tgt.size(-1)).type_as(tgt_mask.data))\n",
    "        return tgt_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(data_iter, model, loss_compute):\n",
    "    \"Standard Training and Logging Function\"\n",
    "    start = time.time()\n",
    "    total_tokens = 0\n",
    "    total_loss = 0\n",
    "    tokens = 0\n",
    "    for i, batch in enumerate(data_iter):\n",
    "        out = model.forward(batch.src, batch.trg, \n",
    "                            batch.src_mask, batch.trg_mask)\n",
    "        loss = loss_compute(out, batch.trg_y, batch.ntokens)\n",
    "        total_loss += loss\n",
    "        total_tokens += batch.ntokens\n",
    "        tokens += batch.ntokens\n",
    "        if i % 50 == 1:\n",
    "            elapsed = time.time() - start\n",
    "            print(\"Epoch Step: %d Loss: %f Tokens per Sec: %f\" %\n",
    "                    (i, loss / batch.ntokens, tokens / elapsed))\n",
    "            start = time.time()\n",
    "            tokens = 0\n",
    "    return total_loss / total_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "global max_src_in_batch, max_tgt_in_batch\n",
    "def batch_size_fn(new, count, sofar):\n",
    "    \"Keep augmenting batch and calculate total number of tokens + padding.\"\n",
    "    global max_src_in_batch, max_tgt_in_batch\n",
    "    if count == 1:\n",
    "        max_src_in_batch = 0\n",
    "        max_tgt_in_batch = 0\n",
    "    max_src_in_batch = max(max_src_in_batch,  len(new.src))\n",
    "    max_tgt_in_batch = max(max_tgt_in_batch,  len(new.trg) + 2)\n",
    "    src_elements = count * max_src_in_batch\n",
    "    tgt_elements = count * max_tgt_in_batch\n",
    "    return max(src_elements, tgt_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoamOpt:\n",
    "    \"Optim wrapper that implements rate.\"\n",
    "    def __init__(self, model_size, factor, warmup, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self._step = 0\n",
    "        self.warmup = warmup\n",
    "        self.factor = factor\n",
    "        self.model_size = model_size\n",
    "        self._rate = 0\n",
    "        \n",
    "    def step(self):\n",
    "        \"Update parameters and rate\"\n",
    "        self._step += 1\n",
    "        rate = self.rate()\n",
    "        for p in self.optimizer.param_groups:\n",
    "            p['lr'] = rate\n",
    "        self._rate = rate\n",
    "        self.optimizer.step()\n",
    "        \n",
    "    def rate(self, step = None):\n",
    "        \"Implement `lrate` above\"\n",
    "        if step is None:\n",
    "            step = self._step\n",
    "        return self.factor * \\\n",
    "            (self.model_size ** (-0.5) *\n",
    "            min(step ** (-0.5), step * self.warmup ** (-1.5)))\n",
    "        \n",
    "def get_std_opt(model):\n",
    "    return NoamOpt(model.src_embed[0].d_model, 2, 4000,\n",
    "            torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f28b9daaf10>,\n",
       " <matplotlib.lines.Line2D at 0x7f28b80af6d0>,\n",
       " <matplotlib.lines.Line2D at 0x7f28b80af890>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "opts = [NoamOpt(512, 1, 4000, None), \n",
    "        NoamOpt(512, 1, 8000, None),\n",
    "        NoamOpt(256, 1, 4000, None)]\n",
    "plt.plot(np.arange(1, 20000), [[opt.rate(i) for opt in opts] for i in range(1, 20000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothing(nn.Module):\n",
    "    \"Implement label smoothing.\"\n",
    "    def __init__(self, size, padding_idx, smoothing=0.0):\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        self.criterion = nn.KLDivLoss(size_average=False)\n",
    "        self.padding_idx = padding_idx\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.size = size\n",
    "        self.true_dist = None\n",
    "        \n",
    "    def forward(self, x, target):\n",
    "        assert x.size(1) == self.size\n",
    "        true_dist = x.data.clone()\n",
    "        true_dist.fill_(self.smoothing / (self.size - 2))\n",
    "        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        true_dist[:, self.padding_idx] = 0\n",
    "        mask = torch.nonzero(target.data == self.padding_idx)\n",
    "        if mask.dim() > 0:\n",
    "            true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
    "        self.true_dist = true_dist\n",
    "        return self.criterion(x, Variable(true_dist, requires_grad=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leon/anaconda3/envs/ntm/lib/python3.7/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "crit = LabelSmoothing(5, 0, 0.4)\n",
    "predict = torch.FloatTensor([[0, 0.2, 0.7, 0.1, 0],\n",
    "                             [0, 0.2, 0.7, 0.1, 0], \n",
    "                             [0, 0.2, 0.7, 0.1, 0]])\n",
    "v = crit(Variable(predict.log()), \n",
    "         Variable(torch.LongTensor([2, 1, 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = LabelSmoothing(5, 0, 0.1)\n",
    "def loss(x):\n",
    "    d = x + 3 * 1\n",
    "    predict = torch.FloatTensor([[0, x / d, 1 / d, 1 / d, 1 / d],\n",
    "                                 ])\n",
    "    #print(predict)\n",
    "    return crit(Variable(predict.log()),\n",
    "                 Variable(torch.LongTensor([1]))).data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"LSTM Controller.\"\"\"\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Parameter\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class LSTMController(nn.Module):\n",
    "    \"\"\"An NTM controller based on LSTM.\"\"\"\n",
    "    def __init__(self, num_inputs, num_outputs, num_layers):\n",
    "        super(LSTMController, self).__init__()\n",
    "\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_outputs = num_outputs\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=num_inputs,\n",
    "                            hidden_size=num_outputs,\n",
    "                            num_layers=num_layers)\n",
    "\n",
    "        # The hidden state is a learned parameter\n",
    "        self.lstm_h_bias = Parameter(torch.randn(self.num_layers, 1, self.num_outputs) * 0.05)\n",
    "        self.lstm_c_bias = Parameter(torch.randn(self.num_layers, 1, self.num_outputs) * 0.05)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def create_new_state(self, batch_size):\n",
    "        # Dimension: (num_layers * num_directions, batch, hidden_size)\n",
    "        lstm_h = self.lstm_h_bias.clone().repeat(1, batch_size, 1)\n",
    "        lstm_c = self.lstm_c_bias.clone().repeat(1, batch_size, 1)\n",
    "        return lstm_h, lstm_c\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for p in self.lstm.parameters():\n",
    "            if p.dim() == 1:\n",
    "                nn.init.constant_(p, 0)\n",
    "            else:\n",
    "                stdev = 5 / (np.sqrt(self.num_inputs +  self.num_outputs))\n",
    "                nn.init.uniform_(p, -stdev, stdev)\n",
    "\n",
    "    def size(self):\n",
    "        return self.num_inputs, self.num_outputs\n",
    "\n",
    "    def forward(self, x, prev_state):\n",
    "        x = x.unsqueeze(0)\n",
    "        outp, state = self.lstm(x, prev_state)\n",
    "        return outp.squeeze(0), state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "        self.model_type = 'Transformer'\n",
    "        self.src_mask = None\n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Embedding(ntoken, ninp)\n",
    "        self.ninp = ninp\n",
    "        self.decoder = nn.Linear(ninp, ntoken)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src):\n",
    "        if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
    "            device = src.device\n",
    "            mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
    "            self.src_mask = mask\n",
    "\n",
    "        src = self.encoder(src) * math.sqrt(self.ninp)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, self.src_mask)\n",
    "        output = self.decoder(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"LSTM Controller.\"\"\"\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Parameter\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class TransformerController(nn.Module):\n",
    "    \"\"\"An NTM controller based on transformer.\"\"\"\n",
    "    def __init__(self, num_inputs, num_outputs, num_layers):\n",
    "        super(TransformerController, self).__init__()\n",
    "\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_outputs = num_outputs\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=num_inputs,\n",
    "                            hidden_size=num_outputs,\n",
    "                            num_layers=num_layers)\n",
    "\n",
    "        # The hidden state is a learned parameter\n",
    "        self.lstm_h_bias = Parameter(torch.randn(self.num_layers, 1, self.num_outputs) * 0.05)\n",
    "        self.lstm_c_bias = Parameter(torch.randn(self.num_layers, 1, self.num_outputs) * 0.05)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def create_new_state(self, batch_size):\n",
    "        # Dimension: (num_layers * num_directions, batch, hidden_size)\n",
    "        lstm_h = self.lstm_h_bias.clone().repeat(1, batch_size, 1)\n",
    "        lstm_c = self.lstm_c_bias.clone().repeat(1, batch_size, 1)\n",
    "        return lstm_h, lstm_c\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for p in self.lstm.parameters():\n",
    "            if p.dim() == 1:\n",
    "                nn.init.constant_(p, 0)\n",
    "            else:\n",
    "                stdev = 5 / (np.sqrt(self.num_inputs +  self.num_outputs))\n",
    "                nn.init.uniform_(p, -stdev, stdev)\n",
    "\n",
    "    def size(self):\n",
    "        return self.num_inputs, self.num_outputs\n",
    "\n",
    "    def forward(self, x, prev_state):\n",
    "        x = x.unsqueeze(0)\n",
    "        outp, state = self.lstm(x, prev_state)\n",
    "        return outp.squeeze(0), state\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
